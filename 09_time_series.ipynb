{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis Crash Course for Data Science Assessments\n",
    "\n",
    "**Last Updated:** 25 January 2026\n",
    "\n",
    "This notebook covers time series analysis concepts commonly tested in data science interviews. We focus on understanding time series components, stationarity, forecasting models, and evaluation techniques.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction and Setup](#1-introduction-and-setup)\n",
    "2. [Time Series Components](#2-time-series-components)\n",
    "3. [Stationarity](#3-stationarity)\n",
    "4. [Autocorrelation (ACF and PACF)](#4-autocorrelation-acf-and-pacf)\n",
    "5. [Moving Averages and Smoothing](#5-moving-averages-and-smoothing)\n",
    "6. [ARIMA Models](#6-arima-models)\n",
    "7. [Seasonal ARIMA (SARIMA)](#7-seasonal-arima-sarima)\n",
    "8. [Exponential Smoothing](#8-exponential-smoothing)\n",
    "9. [Time Series Cross-Validation](#9-time-series-cross-validation)\n",
    "10. [Forecasting Metrics](#10-forecasting-metrics)\n",
    "11. [Feature Engineering for Time Series](#11-feature-engineering-for-time-series)\n",
    "12. [Practice Questions](#12-practice-questions)\n",
    "13. [Summary](#13-summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Setup\n",
    "\n",
    "**Time series** data is a sequence of observations recorded at successive time intervals. Unlike cross-sectional data, the order matters and observations are often correlated.\n",
    "\n",
    "**Key Characteristics:**\n",
    "- **Temporal ordering**: Data points have a natural sequence\n",
    "- **Autocorrelation**: Past values influence future values\n",
    "- **Non-exchangeability**: Cannot randomly shuffle observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sample Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_timeseries(\n",
    "    n_points: int = 365,\n",
    "    trend: float = 0.05,\n",
    "    seasonality_period: int = 30,\n",
    "    seasonality_amplitude: float = 10,\n",
    "    noise_std: float = 2\n",
    ") -> pd.Series:\n",
    "    \"\"\"Create a synthetic time series with trend, seasonality, and noise.\n",
    "    \n",
    "    Args:\n",
    "        n_points: Number of data points.\n",
    "        trend: Linear trend coefficient.\n",
    "        seasonality_period: Period of seasonal component.\n",
    "        seasonality_amplitude: Amplitude of seasonal component.\n",
    "        noise_std: Standard deviation of random noise.\n",
    "    \n",
    "    Returns:\n",
    "        Pandas Series with datetime index.\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(start='2024-01-01', periods=n_points, freq='D')\n",
    "    t = np.arange(n_points)\n",
    "    \n",
    "    trend_component = 100 + trend * t\n",
    "    seasonal_component = seasonality_amplitude * np.sin(2 * np.pi * t / seasonality_period)\n",
    "    noise_component = np.random.normal(0, noise_std, n_points)\n",
    "    \n",
    "    values = trend_component + seasonal_component + noise_component\n",
    "    \n",
    "    return pd.Series(values, index=dates, name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = create_sample_timeseries()\n",
    "\n",
    "print(f\"Time series shape: {ts.shape}\")\n",
    "print(f\"Date range: {ts.index.min()} to {ts.index.max()}\")\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(ts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(ts.index, ts.values, linewidth=0.8)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Sample Time Series with Trend, Seasonality, and Noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Time Series Components\n",
    "\n",
    "A time series can be decomposed into:\n",
    "\n",
    "| Component | Description | Example |\n",
    "|-----------|-------------|--------|\n",
    "| **Trend** | Long-term increase or decrease | Population growth |\n",
    "| **Seasonality** | Regular periodic patterns | Monthly sales cycles |\n",
    "| **Cyclical** | Irregular long-term fluctuations | Business cycles |\n",
    "| **Residual** | Random noise | Unpredictable variations |\n",
    "\n",
    "**Decomposition Types:**\n",
    "- **Additive**: $Y_t = T_t + S_t + R_t$ (constant seasonal amplitude)\n",
    "- **Multiplicative**: $Y_t = T_t \\times S_t \\times R_t$ (seasonal amplitude proportional to level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_timeseries(\n",
    "    ts: pd.Series,\n",
    "    model: str = 'additive',\n",
    "    period: int = None\n",
    ") -> Dict[str, pd.Series]:\n",
    "    \"\"\"Decompose time series into components.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        model: 'additive' or 'multiplicative'.\n",
    "        period: Seasonal period (auto-detected if None).\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with trend, seasonal, and residual components.\n",
    "    \"\"\"\n",
    "    decomposition = seasonal_decompose(ts, model=model, period=period)\n",
    "    \n",
    "    return {\n",
    "        'trend': decomposition.trend,\n",
    "        'seasonal': decomposition.seasonal,\n",
    "        'residual': decomposition.resid,\n",
    "        'observed': decomposition.observed\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = decompose_timeseries(ts, model='additive', period=30)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "\n",
    "axes[0].plot(components['observed'])\n",
    "axes[0].set_ylabel('Observed')\n",
    "axes[0].set_title('Time Series Decomposition')\n",
    "\n",
    "axes[1].plot(components['trend'])\n",
    "axes[1].set_ylabel('Trend')\n",
    "\n",
    "axes[2].plot(components['seasonal'])\n",
    "axes[2].set_ylabel('Seasonal')\n",
    "\n",
    "axes[3].plot(components['residual'])\n",
    "axes[3].set_ylabel('Residual')\n",
    "axes[3].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Stationarity\n",
    "\n",
    "**Stationarity** means statistical properties (mean, variance, autocorrelation) don't change over time. Most forecasting models require stationary data.\n",
    "\n",
    "**Types of Stationarity:**\n",
    "- **Strict stationarity**: Full probability distribution is time-invariant\n",
    "- **Weak stationarity**: Mean and autocovariance are time-invariant\n",
    "\n",
    "**Common Tests:**\n",
    "\n",
    "| Test | Null Hypothesis | Reject if |\n",
    "|------|-----------------|----------|\n",
    "| ADF (Augmented Dickey-Fuller) | Has unit root (non-stationary) | p < 0.05 |\n",
    "| KPSS | Is stationary | p < 0.05 |\n",
    "\n",
    "**Making Data Stationary:**\n",
    "- Differencing (remove trend)\n",
    "- Seasonal differencing (remove seasonality)\n",
    "- Log transformation (stabilise variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(\n",
    "    ts: pd.Series,\n",
    "    significance: float = 0.05\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Test for stationarity using ADF and KPSS tests.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        significance: Significance level for tests.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with test results.\n",
    "    \"\"\"\n",
    "    ts_clean = ts.dropna()\n",
    "    \n",
    "    adf_result = adfuller(ts_clean, autolag='AIC')\n",
    "    kpss_result = kpss(ts_clean, regression='c', nlags='auto')\n",
    "    \n",
    "    return {\n",
    "        'adf_statistic': adf_result[0],\n",
    "        'adf_pvalue': adf_result[1],\n",
    "        'adf_stationary': adf_result[1] < significance,\n",
    "        'kpss_statistic': kpss_result[0],\n",
    "        'kpss_pvalue': kpss_result[1],\n",
    "        'kpss_stationary': kpss_result[1] >= significance,\n",
    "        'is_stationary': (adf_result[1] < significance) and (kpss_result[1] >= significance)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_stationarity(ts)\n",
    "\n",
    "print(\"Stationarity Test Results:\")\n",
    "print(f\"\\nADF Test:\")\n",
    "print(f\"  Statistic: {results['adf_statistic']:.4f}\")\n",
    "print(f\"  P-value: {results['adf_pvalue']:.4f}\")\n",
    "print(f\"  Stationary (ADF): {results['adf_stationary']}\")\n",
    "\n",
    "print(f\"\\nKPSS Test:\")\n",
    "print(f\"  Statistic: {results['kpss_statistic']:.4f}\")\n",
    "print(f\"  P-value: {results['kpss_pvalue']:.4f}\")\n",
    "print(f\"  Stationary (KPSS): {results['kpss_stationary']}\")\n",
    "\n",
    "print(f\"\\nOverall: {'Stationary' if results['is_stationary'] else 'Non-stationary'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differencing to Achieve Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stationary(\n",
    "    ts: pd.Series,\n",
    "    max_diff: int = 2\n",
    ") -> Tuple[pd.Series, int]:\n",
    "    \"\"\"Apply differencing to make series stationary.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        max_diff: Maximum number of differences to try.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (stationary series, number of differences applied).\n",
    "    \"\"\"\n",
    "    diff_order = 0\n",
    "    ts_diff = ts.copy()\n",
    "    \n",
    "    for d in range(max_diff + 1):\n",
    "        results = test_stationarity(ts_diff)\n",
    "        if results['adf_stationary']:\n",
    "            diff_order = d\n",
    "            break\n",
    "        ts_diff = ts_diff.diff().dropna()\n",
    "        diff_order = d + 1\n",
    "    \n",
    "    return ts_diff, diff_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_stationary, d = make_stationary(ts)\n",
    "print(f\"Differences needed: {d}\")\n",
    "\n",
    "results_after = test_stationarity(ts_stationary)\n",
    "print(f\"Stationary after differencing: {results_after['adf_stationary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(ts)\n",
    "axes[0].set_title('Original Series (Non-stationary)')\n",
    "axes[0].set_ylabel('Value')\n",
    "\n",
    "axes[1].plot(ts_stationary)\n",
    "axes[1].set_title(f'Differenced Series (d={d})')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Autocorrelation (ACF and PACF)\n",
    "\n",
    "**Autocorrelation Function (ACF)**: Correlation between a series and its lagged values.\n",
    "\n",
    "**Partial Autocorrelation Function (PACF)**: Correlation between a series and its lag, controlling for intermediate lags.\n",
    "\n",
    "**Interpreting ACF/PACF for ARIMA:**\n",
    "\n",
    "| Pattern | ACF | PACF | Model |\n",
    "|---------|-----|------|-------|\n",
    "| AR(p) | Gradual decay | Cuts off at lag p | AR |\n",
    "| MA(q) | Cuts off at lag q | Gradual decay | MA |\n",
    "| ARMA | Gradual decay | Gradual decay | ARMA |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(\n",
    "    ts: pd.Series,\n",
    "    lags: int = 40\n",
    ") -> None:\n",
    "    \"\"\"Plot ACF and PACF for a time series.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        lags: Number of lags to display.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    plot_acf(ts.dropna(), lags=lags, ax=axes[0])\n",
    "    axes[0].set_title('Autocorrelation Function (ACF)')\n",
    "    \n",
    "    plot_pacf(ts.dropna(), lags=lags, ax=axes[1])\n",
    "    axes[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACF/PACF of original series:\")\n",
    "plot_acf_pacf(ts)\n",
    "\n",
    "print(\"\\nACF/PACF of differenced series:\")\n",
    "plot_acf_pacf(ts_stationary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acf_manual(\n",
    "    ts: pd.Series,\n",
    "    max_lag: int = 10\n",
    ") -> List[float]:\n",
    "    \"\"\"Compute ACF manually.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        max_lag: Maximum lag to compute.\n",
    "    \n",
    "    Returns:\n",
    "        List of autocorrelation values.\n",
    "    \"\"\"\n",
    "    ts_values = ts.dropna().values\n",
    "    n = len(ts_values)\n",
    "    mean = np.mean(ts_values)\n",
    "    var = np.var(ts_values)\n",
    "    \n",
    "    acf_values = []\n",
    "    for lag in range(max_lag + 1):\n",
    "        if lag == 0:\n",
    "            acf_values.append(1.0)\n",
    "        else:\n",
    "            covariance = np.sum((ts_values[:-lag] - mean) * (ts_values[lag:] - mean)) / n\n",
    "            acf_values.append(covariance / var)\n",
    "    \n",
    "    return acf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_acf = compute_acf_manual(ts_stationary, max_lag=10)\n",
    "statsmodels_acf = acf(ts_stationary.dropna(), nlags=10)\n",
    "\n",
    "print(\"ACF Comparison (first 5 lags):\")\n",
    "print(f\"{'Lag':<5} {'Manual':<12} {'Statsmodels':<12}\")\n",
    "for i in range(5):\n",
    "    print(f\"{i:<5} {manual_acf[i]:<12.4f} {statsmodels_acf[i]:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Moving Averages and Smoothing\n",
    "\n",
    "**Moving averages** smooth out short-term fluctuations to reveal underlying trends.\n",
    "\n",
    "| Type | Formula | Use Case |\n",
    "|------|---------|----------|\n",
    "| Simple (SMA) | Unweighted mean of last n values | Trend identification |\n",
    "| Weighted (WMA) | Weighted mean, recent values weighted more | Trend following |\n",
    "| Exponential (EMA) | Exponentially decaying weights | Quick response to changes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_moving_averages(\n",
    "    ts: pd.Series,\n",
    "    windows: List[int] = [7, 14, 30]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute multiple moving averages.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        windows: List of window sizes.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with original and moving averages.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'original': ts})\n",
    "    \n",
    "    for window in windows:\n",
    "        df[f'SMA_{window}'] = ts.rolling(window=window).mean()\n",
    "        df[f'EMA_{window}'] = ts.ewm(span=window, adjust=False).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_df = compute_moving_averages(ts, windows=[7, 30])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ma_df['original'], alpha=0.5, label='Original', linewidth=0.8)\n",
    "plt.plot(ma_df['SMA_7'], label='SMA 7-day', linewidth=1.5)\n",
    "plt.plot(ma_df['SMA_30'], label='SMA 30-day', linewidth=1.5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Simple Moving Averages')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ARIMA Models\n",
    "\n",
    "**ARIMA** (AutoRegressive Integrated Moving Average) is a popular forecasting model combining:\n",
    "\n",
    "- **AR(p)**: Autoregressive - uses past values\n",
    "- **I(d)**: Integrated - differencing for stationarity\n",
    "- **MA(q)**: Moving Average - uses past forecast errors\n",
    "\n",
    "**Model Equation:**\n",
    "$$y'_t = c + \\phi_1 y'_{t-1} + ... + \\phi_p y'_{t-p} + \\theta_1 \\epsilon_{t-1} + ... + \\theta_q \\epsilon_{t-q} + \\epsilon_t$$\n",
    "\n",
    "Where $y'_t$ is the differenced series.\n",
    "\n",
    "**Selecting Parameters (p, d, q):**\n",
    "1. **d**: Number of differences to achieve stationarity\n",
    "2. **p**: PACF cutoff lag\n",
    "3. **q**: ACF cutoff lag\n",
    "4. **AIC/BIC**: Information criteria for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_arima(\n",
    "    ts: pd.Series,\n",
    "    order: Tuple[int, int, int] = (1, 1, 1)\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Fit ARIMA model.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        order: (p, d, q) order of the model.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with model, summary, and diagnostics.\n",
    "    \"\"\"\n",
    "    model = ARIMA(ts, order=order)\n",
    "    fitted = model.fit()\n",
    "    \n",
    "    return {\n",
    "        'model': fitted,\n",
    "        'aic': fitted.aic,\n",
    "        'bic': fitted.bic,\n",
    "        'order': order,\n",
    "        'residuals': fitted.resid\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result = fit_arima(ts, order=(2, 1, 2))\n",
    "\n",
    "print(f\"ARIMA{arima_result['order']} Results:\")\n",
    "print(f\"AIC: {arima_result['aic']:.2f}\")\n",
    "print(f\"BIC: {arima_result['bic']:.2f}\")\n",
    "print(\"\\nModel Summary:\")\n",
    "print(arima_result['model'].summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_arima(\n",
    "    ts: pd.Series,\n",
    "    p_range: range = range(0, 3),\n",
    "    d_range: range = range(0, 2),\n",
    "    q_range: range = range(0, 3)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Grid search for optimal ARIMA parameters.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        p_range: Range of p values.\n",
    "        d_range: Range of d values.\n",
    "        q_range: Range of q values.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with parameter combinations and AIC scores.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for p in p_range:\n",
    "        for d in d_range:\n",
    "            for q in q_range:\n",
    "                try:\n",
    "                    model = ARIMA(ts, order=(p, d, q))\n",
    "                    fitted = model.fit()\n",
    "                    results.append({\n",
    "                        'order': (p, d, q),\n",
    "                        'aic': fitted.aic,\n",
    "                        'bic': fitted.bic\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df.sort_values('aic').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = grid_search_arima(ts)\n",
    "print(\"Top 5 ARIMA models by AIC:\")\n",
    "print(grid_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_arima(\n",
    "    ts: pd.Series,\n",
    "    order: Tuple[int, int, int],\n",
    "    steps: int = 30\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate forecasts with confidence intervals.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        order: ARIMA order (p, d, q).\n",
    "        steps: Number of steps to forecast.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with forecasts and confidence intervals.\n",
    "    \"\"\"\n",
    "    model = ARIMA(ts, order=order)\n",
    "    fitted = model.fit()\n",
    "    \n",
    "    forecast = fitted.get_forecast(steps=steps)\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'forecast': forecast.predicted_mean,\n",
    "        'lower_ci': forecast.conf_int().iloc[:, 0],\n",
    "        'upper_ci': forecast.conf_int().iloc[:, 1]\n",
    "    })\n",
    "    \n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_order = grid_results.iloc[0]['order']\n",
    "forecast_df = forecast_arima(ts, order=best_order, steps=30)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ts[-60:], label='Historical', linewidth=1.5)\n",
    "plt.plot(forecast_df.index, forecast_df['forecast'], label='Forecast', color='red', linewidth=1.5)\n",
    "plt.fill_between(\n",
    "    forecast_df.index,\n",
    "    forecast_df['lower_ci'],\n",
    "    forecast_df['upper_ci'],\n",
    "    color='red', alpha=0.2, label='95% CI'\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'ARIMA{best_order} Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Seasonal ARIMA (SARIMA)\n",
    "\n",
    "**SARIMA** extends ARIMA to handle seasonality with notation: ARIMA(p,d,q)(P,D,Q)[m]\n",
    "\n",
    "- **(p, d, q)**: Non-seasonal components\n",
    "- **(P, D, Q)**: Seasonal components\n",
    "- **[m]**: Seasonal period (e.g., 12 for monthly data with yearly seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sarima(\n",
    "    ts: pd.Series,\n",
    "    order: Tuple[int, int, int] = (1, 1, 1),\n",
    "    seasonal_order: Tuple[int, int, int, int] = (1, 1, 1, 12)\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Fit SARIMA model.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        order: (p, d, q) non-seasonal order.\n",
    "        seasonal_order: (P, D, Q, m) seasonal order.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with model and diagnostics.\n",
    "    \"\"\"\n",
    "    model = SARIMAX(ts, order=order, seasonal_order=seasonal_order)\n",
    "    fitted = model.fit(disp=False)\n",
    "    \n",
    "    return {\n",
    "        'model': fitted,\n",
    "        'aic': fitted.aic,\n",
    "        'bic': fitted.bic,\n",
    "        'order': order,\n",
    "        'seasonal_order': seasonal_order\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_result = fit_sarima(ts, order=(1, 1, 1), seasonal_order=(1, 0, 1, 30))\n",
    "\n",
    "print(f\"SARIMA{sarima_result['order']}x{sarima_result['seasonal_order']} Results:\")\n",
    "print(f\"AIC: {sarima_result['aic']:.2f}\")\n",
    "print(f\"BIC: {sarima_result['bic']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Exponential Smoothing\n",
    "\n",
    "**Exponential smoothing** methods use weighted averages of past observations, with weights decaying exponentially.\n",
    "\n",
    "| Method | Components | Use Case |\n",
    "|--------|------------|----------|\n",
    "| Simple (SES) | Level only | No trend, no seasonality |\n",
    "| Holt | Level + Trend | Trend, no seasonality |\n",
    "| Holt-Winters | Level + Trend + Seasonal | Trend and seasonality |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_exponential_smoothing(\n",
    "    ts: pd.Series,\n",
    "    trend: str = 'add',\n",
    "    seasonal: str = 'add',\n",
    "    seasonal_periods: int = 30\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Fit Holt-Winters exponential smoothing model.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        trend: 'add', 'mul', or None.\n",
    "        seasonal: 'add', 'mul', or None.\n",
    "        seasonal_periods: Number of periods in a season.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with model and parameters.\n",
    "    \"\"\"\n",
    "    model = ExponentialSmoothing(\n",
    "        ts,\n",
    "        trend=trend,\n",
    "        seasonal=seasonal,\n",
    "        seasonal_periods=seasonal_periods\n",
    "    )\n",
    "    fitted = model.fit()\n",
    "    \n",
    "    return {\n",
    "        'model': fitted,\n",
    "        'aic': fitted.aic,\n",
    "        'alpha': fitted.params.get('smoothing_level', None),\n",
    "        'beta': fitted.params.get('smoothing_trend', None),\n",
    "        'gamma': fitted.params.get('smoothing_seasonal', None)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_result = fit_exponential_smoothing(ts, trend='add', seasonal='add', seasonal_periods=30)\n",
    "\n",
    "print(\"Holt-Winters Parameters:\")\n",
    "print(f\"Alpha (level): {hw_result['alpha']:.4f}\")\n",
    "print(f\"Beta (trend): {hw_result['beta']:.4f}\")\n",
    "print(f\"Gamma (seasonal): {hw_result['gamma']:.4f}\")\n",
    "print(f\"AIC: {hw_result['aic']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_forecast = hw_result['model'].forecast(steps=30)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ts[-60:], label='Historical', linewidth=1.5)\n",
    "plt.plot(hw_forecast.index, hw_forecast.values, label='Holt-Winters Forecast', \n",
    "         color='green', linewidth=1.5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Holt-Winters Exponential Smoothing Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Time Series Cross-Validation\n",
    "\n",
    "**Standard cross-validation doesn't work** for time series because:\n",
    "- Data is temporally ordered\n",
    "- Cannot use future data to predict past\n",
    "\n",
    "**Walk-Forward Validation:**\n",
    "1. Train on observations 1 to t\n",
    "2. Forecast observation t+1\n",
    "3. Expand training window and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(\n",
    "    ts: pd.Series,\n",
    "    model_func,\n",
    "    initial_train_size: int = 200,\n",
    "    horizon: int = 1,\n",
    "    step: int = 1\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Perform walk-forward cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data.\n",
    "        model_func: Function that fits model and returns forecast.\n",
    "        initial_train_size: Initial training window size.\n",
    "        horizon: Forecast horizon.\n",
    "        step: Step size between windows.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with predictions, actuals, and metrics.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for i in range(initial_train_size, len(ts) - horizon + 1, step):\n",
    "        train = ts[:i]\n",
    "        test = ts[i:i + horizon]\n",
    "        \n",
    "        pred = model_func(train, horizon)\n",
    "        \n",
    "        predictions.extend(pred.values)\n",
    "        actuals.extend(test.values)\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    mape = np.mean(np.abs((np.array(actuals) - np.array(predictions)) / np.array(actuals))) * 100\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'actuals': actuals,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_forecast_func(train: pd.Series, horizon: int) -> pd.Series:\n",
    "    \"\"\"Helper function for ARIMA forecasting in CV.\"\"\"\n",
    "    model = ARIMA(train, order=(1, 1, 1))\n",
    "    fitted = model.fit()\n",
    "    return fitted.forecast(steps=horizon)\n",
    "\n",
    "\n",
    "cv_results = time_series_cv(ts, arima_forecast_func, initial_train_size=300, horizon=1, step=5)\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"MAE: {cv_results['mae']:.4f}\")\n",
    "print(f\"RMSE: {cv_results['rmse']:.4f}\")\n",
    "print(f\"MAPE: {cv_results['mape']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Forecasting Metrics\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| MAE | $\\frac{1}{n}\\sum|y_i - \\hat{y}_i|$ | Average absolute error |\n",
    "| MSE | $\\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2$ | Penalises large errors |\n",
    "| RMSE | $\\sqrt{MSE}$ | Same units as data |\n",
    "| MAPE | $\\frac{100}{n}\\sum|\\frac{y_i - \\hat{y}_i}{y_i}|$ | Percentage error |\n",
    "| SMAPE | $\\frac{100}{n}\\sum\\frac{2|y_i - \\hat{y}_i|}{|y_i| + |\\hat{y}_i|}$ | Symmetric percentage |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forecast_metrics(\n",
    "    actual: np.ndarray,\n",
    "    predicted: np.ndarray\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Calculate common forecasting metrics.\n",
    "    \n",
    "    Args:\n",
    "        actual: Actual values.\n",
    "        predicted: Predicted values.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics.\n",
    "    \"\"\"\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "    mse = np.mean((actual - predicted) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    non_zero_mask = actual != 0\n",
    "    mape = np.mean(np.abs((actual[non_zero_mask] - predicted[non_zero_mask]) / actual[non_zero_mask])) * 100\n",
    "    \n",
    "    smape = np.mean(2 * np.abs(actual - predicted) / (np.abs(actual) + np.abs(predicted))) * 100\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'SMAPE': smape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_forecast_metrics(cv_results['actuals'], cv_results['predictions'])\n",
    "\n",
    "print(\"Forecast Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Feature Engineering for Time Series\n",
    "\n",
    "For machine learning approaches, you need to create features from the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ts_features(ts: pd.Series, lags: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"Create time series features for ML models.\n",
    "    \n",
    "    Args:\n",
    "        ts: Time series data with datetime index.\n",
    "        lags: Number of lag features.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with engineered features.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(index=ts.index)\n",
    "    df['value'] = ts.values\n",
    "    \n",
    "    # Lag features\n",
    "    for lag in range(1, lags + 1):\n",
    "        df[f'lag_{lag}'] = ts.shift(lag).values\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df['rolling_mean_7'] = ts.rolling(window=7).mean().values\n",
    "    df['rolling_std_7'] = ts.rolling(window=7).std().values\n",
    "    df['rolling_mean_30'] = ts.rolling(window=30).mean().values\n",
    "    \n",
    "    # Date features\n",
    "    df['day_of_week'] = ts.index.dayofweek\n",
    "    df['day_of_month'] = ts.index.day\n",
    "    df['month'] = ts.index.month\n",
    "    df['is_weekend'] = (ts.index.dayofweek >= 5).astype(int)\n",
    "    \n",
    "    # Difference features\n",
    "    df['diff_1'] = ts.diff(1).values\n",
    "    df['diff_7'] = ts.diff(7).values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = create_ts_features(ts, lags=7)\n",
    "print(f\"Created {len(features_df.columns)} features:\")\n",
    "print(features_df.columns.tolist())\n",
    "print(f\"\\nSample:\")\n",
    "print(features_df.dropna().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. Practice Questions\n\nTest your understanding with these interview-style questions. Try to solve each question in the empty code cell before revealing the answer."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 1: Stationarity Test from Scratch\n\nImplement a simplified version of the rolling statistics test for stationarity."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nimport pandas as pd\n\ndef rolling_stationarity_test(\n    ts: pd.Series,\n    window: int = 50,\n    threshold: float = 0.1\n) -> dict:\n    \"\"\"Test stationarity using rolling mean and std.\n    \n    Args:\n        ts: Time series data.\n        window: Rolling window size.\n        threshold: Variation threshold for stationarity.\n    \n    Returns:\n        Dictionary with test results.\n    \"\"\"\n    rolling_mean = ts.rolling(window=window).mean()\n    rolling_std = ts.rolling(window=window).std()\n    \n    # Check if rolling statistics are stable\n    mean_variation = rolling_mean.std() / rolling_mean.mean()\n    std_variation = rolling_std.std() / rolling_std.mean()\n    \n    is_stationary = (mean_variation < threshold) and (std_variation < threshold)\n    \n    return {\n        'mean_variation': mean_variation,\n        'std_variation': std_variation,\n        'is_stationary': is_stationary\n    }\n\n\n# Test\nts = create_sample_timeseries()\nresult = rolling_stationarity_test(ts)\nprint(f\"Mean variation: {result['mean_variation']:.4f}\")\nprint(f\"Std variation: {result['std_variation']:.4f}\")\nprint(f\"Stationary: {result['is_stationary']}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 2: Simple Moving Average Forecast\n\nImplement a simple moving average forecasting function."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nimport pandas as pd\n\ndef sma_forecast(\n    ts: pd.Series,\n    window: int = 7,\n    steps: int = 5\n) -> pd.Series:\n    \"\"\"Forecast using simple moving average.\n    \n    Args:\n        ts: Time series data.\n        window: Window size for moving average.\n        steps: Number of steps to forecast.\n    \n    Returns:\n        Series of forecasted values.\n    \"\"\"\n    values = ts.values.tolist()\n    forecasts = []\n    \n    for _ in range(steps):\n        forecast = np.mean(values[-window:])\n        forecasts.append(forecast)\n        values.append(forecast)\n    \n    # Create index for forecasts\n    last_date = ts.index[-1]\n    freq = pd.infer_freq(ts.index)\n    forecast_index = pd.date_range(start=last_date, periods=steps + 1, freq=freq)[1:]\n    \n    return pd.Series(forecasts, index=forecast_index)\n\n\n# Test\nts = create_sample_timeseries()\nforecast = sma_forecast(ts, window=7, steps=5)\nprint(\"SMA Forecast:\")\nprint(forecast)\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 3: ACF from Scratch\n\nImplement autocorrelation function calculation without using statsmodels."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nfrom typing import List\n\ndef acf_from_scratch(\n    ts: np.ndarray,\n    max_lag: int = 20\n) -> List[float]:\n    \"\"\"Calculate ACF from scratch.\n    \n    Args:\n        ts: Time series values.\n        max_lag: Maximum lag to calculate.\n    \n    Returns:\n        List of autocorrelation values.\n    \"\"\"\n    n = len(ts)\n    mean = np.mean(ts)\n    variance = np.sum((ts - mean) ** 2) / n\n    \n    acf_values = []\n    \n    for lag in range(max_lag + 1):\n        if lag == 0:\n            acf_values.append(1.0)\n        else:\n            covariance = np.sum((ts[:-lag] - mean) * (ts[lag:] - mean)) / n\n            acf_values.append(covariance / variance)\n    \n    return acf_values\n\n\n# Test\nts = create_sample_timeseries()\nacf_vals = acf_from_scratch(ts.values, max_lag=10)\nprint(\"ACF values:\")\nfor i, val in enumerate(acf_vals[:5]):\n    print(f\"  Lag {i}: {val:.4f}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 4: Exponential Smoothing from Scratch\n\nImplement simple exponential smoothing."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nfrom typing import Tuple\n\ndef simple_exponential_smoothing(\n    ts: np.ndarray,\n    alpha: float = 0.3,\n    forecast_steps: int = 5\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Simple exponential smoothing from scratch.\n    \n    Args:\n        ts: Time series values.\n        alpha: Smoothing parameter (0 < alpha < 1).\n        forecast_steps: Number of steps to forecast.\n    \n    Returns:\n        Tuple of (smoothed values, forecasts).\n    \"\"\"\n    n = len(ts)\n    smoothed = np.zeros(n)\n    \n    # Initialise with first value\n    smoothed[0] = ts[0]\n    \n    # Apply smoothing\n    for t in range(1, n):\n        smoothed[t] = alpha * ts[t] + (1 - alpha) * smoothed[t-1]\n    \n    # Forecast (flat for SES)\n    forecasts = np.full(forecast_steps, smoothed[-1])\n    \n    return smoothed, forecasts\n\n\n# Test\nts = create_sample_timeseries()\nsmoothed, forecast = simple_exponential_smoothing(ts.values, alpha=0.3, forecast_steps=5)\nprint(f\"Last smoothed value: {smoothed[-1]:.2f}\")\nprint(f\"Forecast: {forecast}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 5: Seasonal Differencing\n\nImplement a function that applies seasonal differencing."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport pandas as pd\n\ndef seasonal_difference(\n    ts: pd.Series,\n    period: int = 12,\n    order: int = 1\n) -> pd.Series:\n    \"\"\"Apply seasonal differencing.\n    \n    Args:\n        ts: Time series data.\n        period: Seasonal period.\n        order: Number of times to difference.\n    \n    Returns:\n        Seasonally differenced series.\n    \"\"\"\n    result = ts.copy()\n    \n    for _ in range(order):\n        result = result - result.shift(period)\n    \n    return result.dropna()\n\n\n# Test\nts = create_sample_timeseries(seasonality_period=30)\nts_diff = seasonal_difference(ts, period=30)\nprint(f\"Original length: {len(ts)}\")\nprint(f\"After seasonal diff: {len(ts_diff)}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 6: MAPE Calculation\n\nImplement MAPE with handling for zero values."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nfrom typing import Optional\n\ndef calculate_mape(\n    actual: np.ndarray,\n    predicted: np.ndarray,\n    epsilon: float = 1e-10\n) -> Optional[float]:\n    \"\"\"Calculate MAPE with zero handling.\n    \n    Args:\n        actual: Actual values.\n        predicted: Predicted values.\n        epsilon: Small value to avoid division by zero.\n    \n    Returns:\n        MAPE value as percentage, or None if cannot calculate.\n    \"\"\"\n    actual = np.array(actual)\n    predicted = np.array(predicted)\n    \n    # Mask for non-zero actual values\n    non_zero_mask = np.abs(actual) > epsilon\n    \n    if not np.any(non_zero_mask):\n        return None\n    \n    mape = np.mean(\n        np.abs((actual[non_zero_mask] - predicted[non_zero_mask]) / \n               actual[non_zero_mask])\n    ) * 100\n    \n    return mape\n\n\n# Test\nactual = np.array([100, 150, 0, 200, 180])\npredicted = np.array([110, 140, 10, 190, 175])\nmape = calculate_mape(actual, predicted)\nprint(f\"MAPE: {mape:.2f}%\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 7: Walk-Forward Validation\n\nImplement walk-forward validation with expanding window."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom typing import Callable, Dict, List\n\ndef walk_forward_validation(\n    ts: pd.Series,\n    model_func: Callable,\n    min_train: int = 100,\n    horizon: int = 1\n) -> Dict[str, List]:\n    \"\"\"Walk-forward validation with expanding window.\n    \n    Args:\n        ts: Time series data.\n        model_func: Function(train, horizon) -> predictions.\n        min_train: Minimum training size.\n        horizon: Forecast horizon.\n    \n    Returns:\n        Dictionary with predictions and actuals.\n    \"\"\"\n    predictions = []\n    actuals = []\n    \n    for i in range(min_train, len(ts) - horizon + 1):\n        train = ts[:i]\n        test = ts[i:i + horizon]\n        \n        pred = model_func(train, horizon)\n        \n        predictions.extend(pred if hasattr(pred, '__iter__') else [pred])\n        actuals.extend(test.values)\n    \n    return {\n        'predictions': predictions,\n        'actuals': actuals\n    }\n\n\n# Test\ndef naive_forecast(train, horizon):\n    return [train.iloc[-1]] * horizon\n\nts = create_sample_timeseries(n_points=150)\nresults = walk_forward_validation(ts, naive_forecast, min_train=100)\nprint(f\"Predictions: {len(results['predictions'])}\")\nprint(f\"MAE: {np.mean(np.abs(np.array(results['actuals']) - np.array(results['predictions']))):.4f}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 8: Lag Features\n\nCreate a function that generates lag features for ML models."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport pandas as pd\nfrom typing import List\n\ndef create_lag_features(\n    ts: pd.Series,\n    target_col: str = 'target',\n    lags: List[int] = [1, 2, 3, 7, 14]\n) -> pd.DataFrame:\n    \"\"\"Create lag features for supervised learning.\n    \n    Args:\n        ts: Time series data.\n        target_col: Name for target column.\n        lags: List of lag values.\n    \n    Returns:\n        DataFrame with lag features.\n    \"\"\"\n    df = pd.DataFrame(index=ts.index)\n    df[target_col] = ts.values\n    \n    for lag in lags:\n        df[f'lag_{lag}'] = ts.shift(lag).values\n    \n    return df.dropna()\n\n\n# Test\nts = create_sample_timeseries()\nfeatures = create_lag_features(ts, lags=[1, 7, 30])\nprint(\"Features shape:\", features.shape)\nprint(features.head())\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 9: Trend Removal\n\nImplement trend removal using linear regression."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom typing import Tuple\n\ndef remove_trend(\n    ts: pd.Series\n) -> Tuple[pd.Series, float, float]:\n    \"\"\"Remove linear trend from time series.\n    \n    Args:\n        ts: Time series data.\n    \n    Returns:\n        Tuple of (detrended series, slope, intercept).\n    \"\"\"\n    t = np.arange(len(ts))\n    \n    # Fit linear trend\n    slope, intercept = np.polyfit(t, ts.values, 1)\n    \n    # Remove trend\n    trend = slope * t + intercept\n    detrended = pd.Series(ts.values - trend, index=ts.index)\n    \n    return detrended, slope, intercept\n\n\n# Test\nts = create_sample_timeseries(trend=0.1)\ndetrended, slope, intercept = remove_trend(ts)\nprint(f\"Slope: {slope:.4f}\")\nprint(f\"Intercept: {intercept:.4f}\")\nprint(f\"Original mean: {ts.mean():.2f}\")\nprint(f\"Detrended mean: {detrended.mean():.2f}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 10: Naive Forecasting Methods\n\nImplement multiple naive forecasting baselines."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict\n\ndef naive_forecasts(\n    ts: pd.Series,\n    steps: int = 5,\n    seasonal_period: int = 7\n) -> Dict[str, np.ndarray]:\n    \"\"\"Generate multiple naive forecasts.\n    \n    Args:\n        ts: Time series data.\n        steps: Forecast horizon.\n        seasonal_period: Period for seasonal naive.\n    \n    Returns:\n        Dictionary of forecast arrays.\n    \"\"\"\n    forecasts = {}\n    \n    # Last value (naive)\n    forecasts['naive'] = np.full(steps, ts.iloc[-1])\n    \n    # Mean\n    forecasts['mean'] = np.full(steps, ts.mean())\n    \n    # Drift (last value + average change)\n    avg_change = (ts.iloc[-1] - ts.iloc[0]) / (len(ts) - 1)\n    forecasts['drift'] = ts.iloc[-1] + avg_change * np.arange(1, steps + 1)\n    \n    # Seasonal naive\n    seasonal_forecasts = []\n    for i in range(steps):\n        idx = -(seasonal_period - (i % seasonal_period))\n        seasonal_forecasts.append(ts.iloc[idx])\n    forecasts['seasonal_naive'] = np.array(seasonal_forecasts)\n    \n    return forecasts\n\n\n# Test\nts = create_sample_timeseries()\nforecasts = naive_forecasts(ts, steps=5, seasonal_period=30)\nfor method, values in forecasts.items():\n    print(f\"{method}: {values}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 11: Detect Seasonality Period\n\nImplement a function to detect the dominant seasonal period."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nimport pandas as pd\n\ndef detect_seasonality(\n    ts: pd.Series,\n    max_period: int = 60\n) -> int:\n    \"\"\"Detect dominant seasonal period using ACF.\n    \n    Args:\n        ts: Time series data.\n        max_period: Maximum period to check.\n    \n    Returns:\n        Detected seasonal period.\n    \"\"\"\n    from statsmodels.tsa.stattools import acf\n    \n    # Compute ACF\n    acf_values = acf(ts.dropna(), nlags=max_period)\n    \n    # Find peaks (local maxima) excluding lag 0\n    peaks = []\n    for i in range(2, len(acf_values) - 1):\n        if acf_values[i] > acf_values[i-1] and acf_values[i] > acf_values[i+1]:\n            peaks.append((i, acf_values[i]))\n    \n    if not peaks:\n        return 1  # No seasonality detected\n    \n    # Return lag with highest ACF peak\n    dominant_period = max(peaks, key=lambda x: x[1])[0]\n    \n    return dominant_period\n\n\n# Test\nts = create_sample_timeseries(seasonality_period=30)\nperiod = detect_seasonality(ts)\nprint(f\"Detected seasonal period: {period}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Question 12: Model Comparison\n\nCompare multiple forecasting models and return the best one."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your solution here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Click to reveal answer</summary>\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\n\ndef compare_models(\n    ts: pd.Series,\n    test_size: int = 30\n) -> Dict[str, Dict]:\n    \"\"\"Compare forecasting models on held-out test set.\n    \n    Args:\n        ts: Time series data.\n        test_size: Size of test set.\n    \n    Returns:\n        Dictionary with model results.\n    \"\"\"\n    train = ts[:-test_size]\n    test = ts[-test_size:]\n    \n    results = {}\n    \n    # Naive\n    naive_pred = np.full(test_size, train.iloc[-1])\n    results['Naive'] = {\n        'predictions': naive_pred,\n        'rmse': np.sqrt(np.mean((test.values - naive_pred) ** 2))\n    }\n    \n    # ARIMA\n    try:\n        arima = ARIMA(train, order=(1, 1, 1)).fit()\n        arima_pred = arima.forecast(steps=test_size)\n        results['ARIMA(1,1,1)'] = {\n            'predictions': arima_pred.values,\n            'rmse': np.sqrt(np.mean((test.values - arima_pred.values) ** 2))\n        }\n    except:\n        pass\n    \n    # Exponential Smoothing\n    try:\n        hw = ExponentialSmoothing(train, trend='add').fit()\n        hw_pred = hw.forecast(steps=test_size)\n        results['ExpSmoothing'] = {\n            'predictions': hw_pred.values,\n            'rmse': np.sqrt(np.mean((test.values - hw_pred.values) ** 2))\n        }\n    except:\n        pass\n    \n    # Find best model\n    best_model = min(results.items(), key=lambda x: x[1]['rmse'])\n    \n    return {\n        'all_results': results,\n        'best_model': best_model[0],\n        'best_rmse': best_model[1]['rmse']\n    }\n\n\n# Test\nts = create_sample_timeseries()\ncomparison = compare_models(ts, test_size=30)\nprint(\"Model Comparison:\")\nfor model, data in comparison['all_results'].items():\n    print(f\"  {model}: RMSE = {data['rmse']:.4f}\")\nprint(f\"\\nBest model: {comparison['best_model']}\")\n```\n\n</details>\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary\n",
    "\n",
    "This notebook covered essential time series concepts:\n",
    "\n",
    "1. **Components**: Trend, seasonality, cyclical patterns, and residuals\n",
    "2. **Stationarity**: ADF and KPSS tests, differencing to achieve stationarity\n",
    "3. **ACF/PACF**: Understanding autocorrelation for model selection\n",
    "4. **Moving Averages**: Simple, weighted, and exponential smoothing\n",
    "5. **ARIMA**: Autoregressive integrated moving average models\n",
    "6. **SARIMA**: Handling seasonality in ARIMA\n",
    "7. **Exponential Smoothing**: Holt-Winters method\n",
    "8. **Cross-Validation**: Walk-forward validation for time series\n",
    "9. **Metrics**: MAE, RMSE, MAPE, SMAPE\n",
    "10. **Feature Engineering**: Lag features, rolling statistics, date features\n",
    "\n",
    "---\n",
    "\n",
    "### Key Interview Tips\n",
    "\n",
    "- **Always check stationarity first**: Most models require stationary data\n",
    "- **Use appropriate CV**: Never use random splits for time series\n",
    "- **Start with baselines**: Naive methods set the performance floor\n",
    "- **Understand ACF/PACF**: They guide ARIMA parameter selection\n",
    "- **Know the metrics**: MAPE is intuitive but fails with zeros; use SMAPE or RMSE\n",
    "- **Feature engineering matters**: Lag features make time series work with ML models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}