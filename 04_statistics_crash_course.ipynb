{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Crash Course for Data Science Interviews\n",
    "\n",
    "**Date:** 20 January 2026\n",
    "\n",
    "This notebook covers essential statistics concepts commonly tested in data science interviews and technical assessments. Each section includes explanations, code examples, and practice questions.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Descriptive Statistics](#1-descriptive-statistics)\n",
    "2. [Probability Basics](#2-probability-basics)\n",
    "3. [Probability Distributions](#3-probability-distributions)\n",
    "4. [Central Limit Theorem](#4-central-limit-theorem)\n",
    "5. [Confidence Intervals](#5-confidence-intervals)\n",
    "6. [Hypothesis Testing](#6-hypothesis-testing)\n",
    "7. [Correlation and Covariance](#7-correlation-and-covariance)\n",
    "8. [A/B Testing Basics](#8-ab-testing-basics)\n",
    "9. [Sampling Methods](#9-sampling-methods)\n",
    "10. [Common Statistical Pitfalls](#10-common-statistical-pitfalls)\n",
    "11. [Practice Questions](#11-practice-questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Descriptive Statistics\n",
    "\n",
    "Descriptive statistics summarise and describe the main features of a dataset. They provide simple summaries about the sample and the measures.\n",
    "\n",
    "### Measures of Central Tendency\n",
    "\n",
    "- **Mean**: The arithmetic average of all values\n",
    "- **Median**: The middle value when data is sorted\n",
    "- **Mode**: The most frequently occurring value\n",
    "\n",
    "### Measures of Dispersion\n",
    "\n",
    "- **Variance**: The average of squared deviations from the mean\n",
    "- **Standard Deviation**: The square root of variance (same units as data)\n",
    "- **Range**: Difference between maximum and minimum values\n",
    "- **Interquartile Range (IQR)**: Range between 25th and 75th percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptive_stats(data: np.ndarray) -> dict:\n",
    "    \"\"\"Calculate comprehensive descriptive statistics for a dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: A numpy array of numerical values.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing all descriptive statistics.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'mean': np.mean(data),\n",
    "        'median': np.median(data),\n",
    "        'mode': stats.mode(data, keepdims=True).mode[0],\n",
    "        'variance': np.var(data, ddof=1),\n",
    "        'std_dev': np.std(data, ddof=1),\n",
    "        'range': np.ptp(data),\n",
    "        'iqr': stats.iqr(data),\n",
    "        'skewness': stats.skew(data),\n",
    "        'kurtosis': stats.kurtosis(data)\n",
    "    }\n",
    "\n",
    "\n",
    "sample_data = np.array([12, 15, 18, 22, 22, 25, 28, 30, 35, 40])\n",
    "desc_stats = calculate_descriptive_stats(sample_data)\n",
    "\n",
    "print(\"Sample Data:\", sample_data)\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "for stat, value in desc_stats.items():\n",
    "    print(f\"  {stat.replace('_', ' ').title()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Each Measure\n",
    "\n",
    "| Measure | Best Used When | Sensitive To |\n",
    "|---------|---------------|---------------|\n",
    "| Mean | Data is symmetric, no outliers | Outliers |\n",
    "| Median | Data is skewed or has outliers | Not sensitive to outliers |\n",
    "| Mode | Categorical data or finding most common value | N/A |\n",
    "| Std Dev | Understanding spread around the mean | Outliers |\n",
    "| IQR | Robust measure of spread | Not sensitive to outliers |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Probability Basics\n",
    "\n",
    "Probability measures the likelihood of an event occurring, ranging from 0 (impossible) to 1 (certain).\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Sample Space (S)**: Set of all possible outcomes\n",
    "- **Event (E)**: A subset of the sample space\n",
    "- **P(E)**: Probability of event E occurring\n",
    "\n",
    "### Probability Rules\n",
    "\n",
    "1. **Addition Rule**: P(A or B) = P(A) + P(B) - P(A and B)\n",
    "2. **Multiplication Rule**: P(A and B) = P(A) * P(B|A)\n",
    "3. **Complement Rule**: P(not A) = 1 - P(A)\n",
    "\n",
    "### Conditional Probability\n",
    "\n",
    "The probability of event A given that event B has occurred:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_probability(p_a_and_b: float, p_b: float) -> float:\n",
    "    \"\"\"Calculate conditional probability P(A|B).\n",
    "    \n",
    "    Args:\n",
    "        p_a_and_b: Probability of both A and B occurring.\n",
    "        p_b: Probability of B occurring.\n",
    "        \n",
    "    Returns:\n",
    "        The conditional probability P(A|B).\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If p_b is zero.\n",
    "    \"\"\"\n",
    "    if p_b == 0:\n",
    "        raise ValueError(\"P(B) cannot be zero\")\n",
    "    return p_a_and_b / p_b\n",
    "\n",
    "\n",
    "p_rain = 0.3\n",
    "p_traffic_given_rain = 0.7\n",
    "p_rain_and_traffic = p_rain * p_traffic_given_rain\n",
    "\n",
    "print(f\"P(Rain) = {p_rain}\")\n",
    "print(f\"P(Traffic | Rain) = {p_traffic_given_rain}\")\n",
    "print(f\"P(Rain and Traffic) = {p_rain_and_traffic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Theorem\n",
    "\n",
    "Bayes' theorem describes the probability of an event based on prior knowledge of conditions related to the event:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "**Example**: Medical diagnosis\n",
    "- A test for a disease is 99% accurate\n",
    "- The disease affects 1% of the population\n",
    "- What is the probability you have the disease if you test positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_theorem(\n",
    "    p_b_given_a: float,\n",
    "    p_a: float,\n",
    "    p_b: float\n",
    ") -> float:\n",
    "    \"\"\"Calculate P(A|B) using Bayes' theorem.\n",
    "    \n",
    "    Args:\n",
    "        p_b_given_a: Probability of B given A (likelihood).\n",
    "        p_a: Prior probability of A.\n",
    "        p_b: Marginal probability of B (evidence).\n",
    "        \n",
    "    Returns:\n",
    "        Posterior probability P(A|B).\n",
    "    \"\"\"\n",
    "    return (p_b_given_a * p_a) / p_b\n",
    "\n",
    "\n",
    "p_disease = 0.01\n",
    "p_positive_given_disease = 0.99\n",
    "p_positive_given_no_disease = 0.01\n",
    "\n",
    "p_positive = (p_positive_given_disease * p_disease + \n",
    "              p_positive_given_no_disease * (1 - p_disease))\n",
    "\n",
    "p_disease_given_positive = bayes_theorem(\n",
    "    p_positive_given_disease, \n",
    "    p_disease, \n",
    "    p_positive\n",
    ")\n",
    "\n",
    "print(f\"Prior P(Disease) = {p_disease:.2%}\")\n",
    "print(f\"P(Positive Test) = {p_positive:.4f}\")\n",
    "print(f\"P(Disease | Positive Test) = {p_disease_given_positive:.2%}\")\n",
    "print(\"\\nNote: Even with a 99% accurate test, only ~50% of positive tests indicate disease!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Probability Distributions\n",
    "\n",
    "A probability distribution describes how the values of a random variable are distributed.\n",
    "\n",
    "### Discrete Distributions\n",
    "\n",
    "#### Binomial Distribution\n",
    "Models the number of successes in n independent Bernoulli trials.\n",
    "\n",
    "- **Parameters**: n (trials), p (probability of success)\n",
    "- **Mean**: np\n",
    "- **Variance**: np(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "p_success = 0.3\n",
    "\n",
    "binomial_dist = stats.binom(n=n_trials, p=p_success)\n",
    "\n",
    "print(f\"Binomial Distribution (n={n_trials}, p={p_success})\")\n",
    "print(f\"Mean: {binomial_dist.mean():.2f}\")\n",
    "print(f\"Variance: {binomial_dist.var():.2f}\")\n",
    "print(f\"P(X = 3): {binomial_dist.pmf(3):.4f}\")  # type: ignore[union-attr]\n",
    "print(f\"P(X <= 3): {binomial_dist.cdf(3):.4f}\")\n",
    "\n",
    "x = np.arange(0, n_trials + 1)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x, binomial_dist.pmf(x), color='steelblue', alpha=0.7)  # type: ignore[union-attr]\n",
    "plt.xlabel('Number of Successes')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Binomial Distribution (n={n_trials}, p={p_success})')\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisson Distribution\n",
    "Models the number of events occurring in a fixed interval of time/space.\n",
    "\n",
    "- **Parameter**: λ (lambda) - average rate of occurrence\n",
    "- **Mean**: λ\n",
    "- **Variance**: λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_rate = 4\n",
    "\n",
    "poisson_dist = stats.poisson(mu=lambda_rate)\n",
    "\n",
    "print(f\"Poisson Distribution (λ={lambda_rate})\")\n",
    "print(f\"Mean: {poisson_dist.mean():.2f}\")\n",
    "print(f\"Variance: {poisson_dist.var():.2f}\")\n",
    "print(f\"P(X = 5): {poisson_dist.pmf(5):.4f}\")  # type: ignore[union-attr]\n",
    "\n",
    "x = np.arange(0, 15)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x, poisson_dist.pmf(x), color='coral', alpha=0.7)  # type: ignore[union-attr]\n",
    "plt.xlabel('Number of Events')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Poisson Distribution (λ={lambda_rate})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Distributions\n",
    "\n",
    "#### Normal (Gaussian) Distribution\n",
    "The most important distribution in statistics - the \"bell curve\".\n",
    "\n",
    "- **Parameters**: μ (mean), σ (standard deviation)\n",
    "- **68-95-99.7 Rule**: 68% within 1σ, 95% within 2σ, 99.7% within 3σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 100, 15\n",
    "\n",
    "normal_dist = stats.norm(loc=mu, scale=sigma)\n",
    "\n",
    "print(f\"Normal Distribution (μ={mu}, σ={sigma})\")\n",
    "print(f\"P(X < 115): {normal_dist.cdf(115):.4f}\")\n",
    "print(f\"P(85 < X < 115): {normal_dist.cdf(115) - normal_dist.cdf(85):.4f}\")\n",
    "print(f\"Value at 95th percentile: {normal_dist.ppf(0.95):.2f}\")\n",
    "\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x, normal_dist.pdf(x), 'b-', linewidth=2)  # type: ignore[union-attr]\n",
    "plt.fill_between(x, normal_dist.pdf(x), alpha=0.3)  # type: ignore[union-attr]\n",
    "plt.axvline(mu, color='red', linestyle='--', label=f'Mean = {mu}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title(f'Normal Distribution (μ={mu}, σ={sigma})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform Distribution\n",
    "All outcomes are equally likely within a given range.\n",
    "\n",
    "- **Parameters**: a (minimum), b (maximum)\n",
    "- **Mean**: (a + b) / 2\n",
    "- **Variance**: (b - a)² / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0, 10\n",
    "\n",
    "uniform_dist = stats.uniform(loc=a, scale=b-a)\n",
    "\n",
    "print(f\"Uniform Distribution (a={a}, b={b})\")\n",
    "print(f\"Mean: {uniform_dist.mean():.2f}\")\n",
    "print(f\"Variance: {uniform_dist.var():.2f}\")\n",
    "print(f\"P(2 < X < 7): {uniform_dist.cdf(7) - uniform_dist.cdf(2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Central Limit Theorem\n",
    "\n",
    "The **Central Limit Theorem (CLT)** states that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the population's distribution.\n",
    "\n",
    "**Key Points:**\n",
    "- Works for any population distribution (with finite variance)\n",
    "- Sample size n ≥ 30 is generally sufficient\n",
    "- Mean of sample means = Population mean (μ)\n",
    "- Standard error = σ / √n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_clt(\n",
    "    population: np.ndarray,\n",
    "    sample_sizes: list[int],\n",
    "    n_samples: int = 1000\n",
    ") -> None:\n",
    "    \"\"\"Demonstrate the Central Limit Theorem visually.\n",
    "    \n",
    "    Args:\n",
    "        population: The population to sample from.\n",
    "        sample_sizes: List of different sample sizes to demonstrate.\n",
    "        n_samples: Number of samples to draw for each sample size.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(sample_sizes) + 1, figsize=(16, 4))\n",
    "    \n",
    "    axes[0].hist(population, bins=50, density=True, alpha=0.7, color='gray')\n",
    "    axes[0].set_title('Population Distribution')\n",
    "    axes[0].set_xlabel('Value')\n",
    "    \n",
    "    for idx, n in enumerate(sample_sizes):\n",
    "        sample_means = [np.mean(np.random.choice(population, size=n)) \n",
    "                        for _ in range(n_samples)]\n",
    "        \n",
    "        axes[idx + 1].hist(sample_means, bins=50, density=True, alpha=0.7)\n",
    "        axes[idx + 1].set_title(f'Sample Means (n={n})')\n",
    "        axes[idx + 1].set_xlabel('Sample Mean')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "exponential_population = np.random.exponential(scale=2, size=100000)\n",
    "demonstrate_clt(exponential_population, [5, 30, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Confidence Intervals\n",
    "\n",
    "A **confidence interval** provides a range of values that likely contains the true population parameter.\n",
    "\n",
    "**Formula for mean (when σ is known):**\n",
    "$$\\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "**Formula for mean (when σ is unknown, use t-distribution):**\n",
    "$$\\bar{x} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_mean(\n",
    "    data: np.ndarray,\n",
    "    confidence: float = 0.95\n",
    ") -> tuple[float, float, float]:\n",
    "    \"\"\"Calculate confidence interval for the mean using t-distribution.\n",
    "    \n",
    "    Args:\n",
    "        data: Sample data array.\n",
    "        confidence: Confidence level (default 0.95 for 95% CI).\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (sample_mean, lower_bound, upper_bound).\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    mean = float(np.mean(data))\n",
    "    se = stats.sem(data)\n",
    "    \n",
    "    t_critical = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
    "    margin_of_error = t_critical * se\n",
    "    \n",
    "    return mean, mean - margin_of_error, mean + margin_of_error\n",
    "\n",
    "\n",
    "sample = np.random.normal(loc=50, scale=10, size=100)\n",
    "mean, ci_lower, ci_upper = confidence_interval_mean(sample, confidence=0.95)\n",
    "\n",
    "print(f\"Sample Mean: {mean:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
    "\n",
    "ci_result = stats.t.interval(0.95, df=len(sample)-1, loc=np.mean(sample), scale=stats.sem(sample))\n",
    "print(f\"Using scipy.stats: ({ci_result[0]:.2f}, {ci_result[1]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Hypothesis Testing\n",
    "\n",
    "Hypothesis testing is a method for making statistical decisions using experimental data.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Null Hypothesis (H₀)**: The default assumption (no effect/difference)\n",
    "- **Alternative Hypothesis (H₁)**: What we want to prove\n",
    "- **p-value**: Probability of observing results at least as extreme as the data, assuming H₀ is true\n",
    "- **Significance Level (α)**: Threshold for rejecting H₀ (typically 0.05)\n",
    "\n",
    "### Types of Errors\n",
    "\n",
    "| | H₀ True | H₀ False |\n",
    "|---|---------|----------|\n",
    "| Reject H₀ | Type I Error (α) | Correct |\n",
    "| Fail to Reject H₀ | Correct | Type II Error (β) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Sample t-test\n",
    "\n",
    "Tests whether the mean of a sample differs from a known value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample_ttest(\n",
    "    sample: np.ndarray,\n",
    "    population_mean: float,\n",
    "    alpha: float = 0.05\n",
    ") -> dict:\n",
    "    \"\"\"Perform a one-sample t-test.\n",
    "    \n",
    "    Args:\n",
    "        sample: Sample data array.\n",
    "        population_mean: Hypothesised population mean.\n",
    "        alpha: Significance level.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with test results.\n",
    "    \"\"\"\n",
    "    result = stats.ttest_1samp(sample, population_mean)\n",
    "    t_stat = float(result[0])  # type: ignore[arg-type]\n",
    "    p_value = float(result[1])  # type: ignore[arg-type]\n",
    "    \n",
    "    return {\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'reject_null': p_value < alpha,\n",
    "        'alpha': alpha\n",
    "    }\n",
    "\n",
    "\n",
    "sample_scores = np.random.normal(loc=72, scale=8, size=50)\n",
    "result = one_sample_ttest(sample_scores, population_mean=70)\n",
    "\n",
    "print(\"One-Sample t-test: Is the mean different from 70?\")\n",
    "print(f\"t-statistic: {result['t_statistic']:.4f}\")\n",
    "print(f\"p-value: {result['p_value']:.4f}\")\n",
    "print(f\"Reject H₀ at α=0.05: {result['reject_null']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Sample t-test\n",
    "\n",
    "Tests whether the means of two independent samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_ttest(\n",
    "    sample1: np.ndarray,\n",
    "    sample2: np.ndarray,\n",
    "    equal_var: bool = False,\n",
    "    alpha: float = 0.05\n",
    ") -> dict:\n",
    "    \"\"\"Perform a two-sample t-test (Welch's t-test by default).\n",
    "    \n",
    "    Args:\n",
    "        sample1: First sample data array.\n",
    "        sample2: Second sample data array.\n",
    "        equal_var: Assume equal variances (False for Welch's test).\n",
    "        alpha: Significance level.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with test results.\n",
    "    \"\"\"\n",
    "    result = stats.ttest_ind(sample1, sample2, equal_var=equal_var)\n",
    "    t_stat = float(result[0])  # type: ignore[arg-type]\n",
    "    p_value = float(result[1])  # type: ignore[arg-type]\n",
    "    \n",
    "    return {\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'reject_null': p_value < alpha,\n",
    "        'mean_diff': float(np.mean(sample1) - np.mean(sample2))\n",
    "    }\n",
    "\n",
    "\n",
    "group_a = np.random.normal(loc=50, scale=10, size=40)\n",
    "group_b = np.random.normal(loc=55, scale=12, size=45)\n",
    "\n",
    "result = two_sample_ttest(group_a, group_b)\n",
    "print(\"Two-Sample t-test: Are the group means different?\")\n",
    "print(f\"Mean difference: {result['mean_diff']:.2f}\")\n",
    "print(f\"t-statistic: {result['t_statistic']:.4f}\")\n",
    "print(f\"p-value: {result['p_value']:.4f}\")\n",
    "print(f\"Reject H₀ at α=0.05: {result['reject_null']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Test\n",
    "\n",
    "Tests the independence of two categorical variables or goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_independence(\n",
    "    contingency_table: np.ndarray,\n",
    "    alpha: float = 0.05\n",
    ") -> dict:\n",
    "    \"\"\"Perform chi-square test of independence.\n",
    "    \n",
    "    Args:\n",
    "        contingency_table: 2D array of observed frequencies.\n",
    "        alpha: Significance level.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with test results.\n",
    "    \"\"\"\n",
    "    result = stats.chi2_contingency(contingency_table)\n",
    "    chi2 = float(result[0])  # type: ignore[arg-type]\n",
    "    p_value = float(result[1])  # type: ignore[arg-type]\n",
    "    dof = int(result[2])  # type: ignore[arg-type]\n",
    "    expected = result[3]\n",
    "    \n",
    "    return {\n",
    "        'chi2_statistic': chi2,\n",
    "        'p_value': p_value,\n",
    "        'degrees_of_freedom': dof,\n",
    "        'expected_frequencies': expected,\n",
    "        'reject_null': p_value < alpha\n",
    "    }\n",
    "\n",
    "\n",
    "observed = np.array([[50, 30], [20, 40]])\n",
    "result = chi_square_independence(observed)\n",
    "\n",
    "print(\"Chi-Square Test of Independence\")\n",
    "print(f\"Observed:\\n{observed}\")\n",
    "print(f\"\\nExpected:\\n{result['expected_frequencies'].round(2)}\")\n",
    "print(f\"\\nChi² statistic: {result['chi2_statistic']:.4f}\")\n",
    "print(f\"p-value: {result['p_value']:.4f}\")\n",
    "print(f\"Reject H₀ (variables are independent): {result['reject_null']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Correlation and Covariance\n",
    "\n",
    "### Covariance\n",
    "Measures how two variables change together. Units depend on the variables.\n",
    "\n",
    "$$Cov(X, Y) = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{n-1}$$\n",
    "\n",
    "### Correlation (Pearson's r)\n",
    "Standardised measure of linear relationship (-1 to +1).\n",
    "\n",
    "$$r = \\frac{Cov(X, Y)}{\\sigma_X \\cdot \\sigma_Y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray\n",
    ") -> dict:\n",
    "    \"\"\"Perform comprehensive correlation analysis.\n",
    "    \n",
    "    Args:\n",
    "        x: First variable array.\n",
    "        y: Second variable array.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with correlation metrics and test results.\n",
    "    \"\"\"\n",
    "    pearson_r, pearson_p = stats.pearsonr(x, y)\n",
    "    spearman_r, spearman_p = stats.spearmanr(x, y)\n",
    "    covariance = np.cov(x, y)[0, 1]\n",
    "    \n",
    "    return {\n",
    "        'covariance': covariance,\n",
    "        'pearson_r': pearson_r,\n",
    "        'pearson_p_value': pearson_p,\n",
    "        'spearman_r': spearman_r,\n",
    "        'spearman_p_value': spearman_p\n",
    "    }\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(50, 10, 100)\n",
    "y = 2 * x + np.random.normal(0, 5, 100)\n",
    "\n",
    "result = correlation_analysis(x, y)\n",
    "\n",
    "print(\"Correlation Analysis\")\n",
    "print(f\"Covariance: {result['covariance']:.4f}\")\n",
    "print(f\"Pearson r: {result['pearson_r']:.4f} (p-value: {result['pearson_p_value']:.2e})\")\n",
    "print(f\"Spearman r: {result['spearman_r']:.4f} (p-value: {result['spearman_p_value']:.2e})\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, alpha=0.6)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title(f'Scatter Plot (Pearson r = {result[\"pearson_r\"]:.3f})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Interpretation\n",
    "\n",
    "| r value | Interpretation |\n",
    "|---------|----------------|\n",
    "| 0.9 to 1.0 | Very strong positive |\n",
    "| 0.7 to 0.9 | Strong positive |\n",
    "| 0.4 to 0.7 | Moderate positive |\n",
    "| 0.1 to 0.4 | Weak positive |\n",
    "| -0.1 to 0.1 | No correlation |\n",
    "\n",
    "**Important**: Correlation does NOT imply causation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. A/B Testing Basics\n",
    "\n",
    "A/B testing is a method of comparing two versions to determine which performs better.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Control Group (A)**: The current/baseline version\n",
    "2. **Treatment Group (B)**: The new version being tested\n",
    "3. **Metric**: What you're measuring (conversion rate, click-through rate, etc.)\n",
    "4. **Sample Size**: Number of observations needed for statistical power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(\n",
    "    baseline_rate: float,\n",
    "    minimum_detectable_effect: float,\n",
    "    alpha: float = 0.05,\n",
    "    power: float = 0.8\n",
    ") -> int:\n",
    "    \"\"\"Calculate required sample size per group for A/B test.\n",
    "    \n",
    "    Args:\n",
    "        baseline_rate: Current conversion rate (e.g., 0.10 for 10%).\n",
    "        minimum_detectable_effect: Minimum relative change to detect.\n",
    "        alpha: Significance level (Type I error rate).\n",
    "        power: Statistical power (1 - Type II error rate).\n",
    "        \n",
    "    Returns:\n",
    "        Required sample size per group.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.power import NormalIndPower\n",
    "    \n",
    "    p1 = baseline_rate\n",
    "    p2 = baseline_rate * (1 + minimum_detectable_effect)\n",
    "    \n",
    "    pooled_p = (p1 + p2) / 2\n",
    "    effect_size = abs(p2 - p1) / np.sqrt(pooled_p * (1 - pooled_p))\n",
    "    \n",
    "    analysis = NormalIndPower()\n",
    "    sample_size = analysis.solve_power(\n",
    "        effect_size=effect_size,\n",
    "        alpha=alpha,\n",
    "        power=power,\n",
    "        alternative='two-sided'\n",
    "    )\n",
    "    \n",
    "    return int(np.ceil(sample_size))\n",
    "\n",
    "\n",
    "required_n = calculate_sample_size(\n",
    "    baseline_rate=0.10,\n",
    "    minimum_detectable_effect=0.10\n",
    ")\n",
    "print(f\"Required sample size per group: {required_n}\")\n",
    "print(f\"Total sample size: {required_n * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_test_proportions(\n",
    "    conversions_a: int,\n",
    "    total_a: int,\n",
    "    conversions_b: int,\n",
    "    total_b: int,\n",
    "    alpha: float = 0.05\n",
    ") -> dict:\n",
    "    \"\"\"Perform A/B test for proportions (e.g., conversion rates).\n",
    "    \n",
    "    Args:\n",
    "        conversions_a: Number of conversions in control group.\n",
    "        total_a: Total observations in control group.\n",
    "        conversions_b: Number of conversions in treatment group.\n",
    "        total_b: Total observations in treatment group.\n",
    "        alpha: Significance level.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with test results and metrics.\n",
    "    \"\"\"\n",
    "    p_a = conversions_a / total_a\n",
    "    p_b = conversions_b / total_b\n",
    "    \n",
    "    count = np.array([conversions_a, conversions_b])\n",
    "    nobs = np.array([total_a, total_b])\n",
    "    \n",
    "    from statsmodels.stats.proportion import proportions_ztest\n",
    "    z_stat, p_value = proportions_ztest(count, nobs, alternative='two-sided')\n",
    "    \n",
    "    relative_lift = (p_b - p_a) / p_a * 100\n",
    "    \n",
    "    return {\n",
    "        'control_rate': p_a,\n",
    "        'treatment_rate': p_b,\n",
    "        'absolute_difference': p_b - p_a,\n",
    "        'relative_lift': relative_lift,\n",
    "        'z_statistic': z_stat,\n",
    "        'p_value': p_value,\n",
    "        'significant': p_value < alpha\n",
    "    }\n",
    "\n",
    "\n",
    "result = ab_test_proportions(\n",
    "    conversions_a=120,\n",
    "    total_a=1000,\n",
    "    conversions_b=150,\n",
    "    total_b=1000\n",
    ")\n",
    "\n",
    "print(\"A/B Test Results\")\n",
    "print(f\"Control conversion rate: {result['control_rate']:.2%}\")\n",
    "print(f\"Treatment conversion rate: {result['treatment_rate']:.2%}\")\n",
    "print(f\"Relative lift: {result['relative_lift']:.1f}%\")\n",
    "print(f\"p-value: {result['p_value']:.4f}\")\n",
    "print(f\"Statistically significant: {result['significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Sampling Methods\n",
    "\n",
    "### Types of Sampling\n",
    "\n",
    "1. **Simple Random Sampling**: Every member has equal chance of selection\n",
    "2. **Stratified Sampling**: Population divided into subgroups, sample from each\n",
    "3. **Cluster Sampling**: Population divided into clusters, randomly select clusters\n",
    "4. **Systematic Sampling**: Select every kth element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_random_sample(\n",
    "    population: np.ndarray,\n",
    "    sample_size: int,\n",
    "    replace: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Draw a simple random sample from a population.\n",
    "    \n",
    "    Args:\n",
    "        population: Array representing the population.\n",
    "        sample_size: Number of elements to sample.\n",
    "        replace: Whether to sample with replacement.\n",
    "        \n",
    "    Returns:\n",
    "        Array containing the sampled elements.\n",
    "    \"\"\"\n",
    "    return np.random.choice(population, size=sample_size, replace=replace)\n",
    "\n",
    "\n",
    "def stratified_sample(\n",
    "    data: pd.DataFrame,\n",
    "    stratify_col: str,\n",
    "    sample_frac: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Draw a stratified sample from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame containing the population.\n",
    "        stratify_col: Column name to stratify by.\n",
    "        sample_frac: Fraction of each stratum to sample.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the stratified sample.\n",
    "    \"\"\"\n",
    "    return data.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=sample_frac)\n",
    "    )\n",
    "\n",
    "\n",
    "def systematic_sample(\n",
    "    population: np.ndarray,\n",
    "    sample_size: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Draw a systematic sample from a population.\n",
    "    \n",
    "    Args:\n",
    "        population: Array representing the population.\n",
    "        sample_size: Number of elements to sample.\n",
    "        \n",
    "    Returns:\n",
    "        Array containing the systematically sampled elements.\n",
    "    \"\"\"\n",
    "    k = len(population) // sample_size\n",
    "    start = np.random.randint(0, k)\n",
    "    indices = np.arange(start, len(population), k)[:sample_size]\n",
    "    return population[indices]\n",
    "\n",
    "\n",
    "population = np.arange(1, 101)\n",
    "\n",
    "srs = simple_random_sample(population, 10)\n",
    "print(f\"Simple Random Sample: {srs}\")\n",
    "\n",
    "sys_sample = systematic_sample(population, 10)\n",
    "print(f\"Systematic Sample: {sys_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Bias\n",
    "\n",
    "Common types of sampling bias to avoid:\n",
    "\n",
    "- **Selection Bias**: Non-random selection of participants\n",
    "- **Survivorship Bias**: Only considering \"survivors\" or successes\n",
    "- **Non-response Bias**: Systematic differences between responders and non-responders\n",
    "- **Convenience Sampling Bias**: Sampling based on easy access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Common Statistical Pitfalls\n",
    "\n",
    "### 1. Correlation vs Causation\n",
    "Just because two variables are correlated does not mean one causes the other.\n",
    "\n",
    "### 2. Simpson's Paradox\n",
    "A trend that appears in groups of data disappears or reverses when the groups are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_a = {'success': 81, 'total': 87, 'rate': 81/87}\n",
    "treatment_b = {'success': 234, 'total': 270, 'rate': 234/270}\n",
    "\n",
    "print(\"Overall Success Rates:\")\n",
    "print(f\"Treatment A: {treatment_a['rate']:.1%}\")\n",
    "print(f\"Treatment B: {treatment_b['rate']:.1%}\")\n",
    "print(\"\\nTreatment A appears better overall!\")\n",
    "\n",
    "print(\"\\nBut when broken down by severity...\")\n",
    "print(\"\\nMild Cases:\")\n",
    "print(f\"Treatment A: 80/80 = 100%\")\n",
    "print(f\"Treatment B: 230/250 = 92%\")\n",
    "\n",
    "print(\"\\nSevere Cases:\")\n",
    "print(f\"Treatment A: 1/7 = 14%\")\n",
    "print(f\"Treatment B: 4/20 = 20%\")\n",
    "\n",
    "print(\"\\nTreatment B is actually better for BOTH mild and severe cases!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. P-hacking\n",
    "Manipulating data or analyses until statistically significant results are achieved.\n",
    "\n",
    "### 4. Multiple Comparisons Problem\n",
    "When performing many tests, some will be significant by chance. Use corrections like Bonferroni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonferroni_correction(\n",
    "    p_values: list[float],\n",
    "    alpha: float = 0.05\n",
    ") -> dict:\n",
    "    \"\"\"Apply Bonferroni correction for multiple comparisons.\n",
    "    \n",
    "    Args:\n",
    "        p_values: List of p-values from multiple tests.\n",
    "        alpha: Family-wise error rate.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with corrected alpha and significant tests.\n",
    "    \"\"\"\n",
    "    n_tests = len(p_values)\n",
    "    corrected_alpha = alpha / n_tests\n",
    "    \n",
    "    significant = [p < corrected_alpha for p in p_values]\n",
    "    \n",
    "    return {\n",
    "        'original_alpha': alpha,\n",
    "        'corrected_alpha': corrected_alpha,\n",
    "        'n_tests': n_tests,\n",
    "        'significant_tests': significant,\n",
    "        'n_significant': sum(significant)\n",
    "    }\n",
    "\n",
    "\n",
    "p_values = [0.001, 0.02, 0.04, 0.06, 0.08]\n",
    "result = bonferroni_correction(p_values)\n",
    "\n",
    "print(f\"Number of tests: {result['n_tests']}\")\n",
    "print(f\"Original α: {result['original_alpha']}\")\n",
    "print(f\"Corrected α: {result['corrected_alpha']:.4f}\")\n",
    "print(f\"\\nSignificant at original α=0.05: {sum(p < 0.05 for p in p_values)}\")\n",
    "print(f\"Significant after Bonferroni correction: {result['n_significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Base Rate Fallacy\n",
    "Ignoring the prior probability when interpreting conditional probabilities (see Bayes' theorem example above).\n",
    "\n",
    "### 6. Regression to the Mean\n",
    "Extreme observations tend to be followed by more moderate ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Practice Questions\n",
    "\n",
    "Test your understanding with these practice problems. Try to solve each one before revealing the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Descriptive Statistics\n",
    "\n",
    "Given the dataset `[23, 45, 67, 32, 45, 89, 12, 45, 78, 34]`, calculate:\n",
    "1. Mean, median, and mode\n",
    "2. Variance and standard deviation\n",
    "3. Which measure of central tendency is most appropriate for this data and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = np.array([23, 45, 67, 32, 45, 89, 12, 45, 78, 34])\n",
    "\n",
    "mean = np.mean(data)\n",
    "median = np.median(data)\n",
    "mode = stats.mode(data, keepdims=True).mode[0]\n",
    "\n",
    "variance = np.var(data, ddof=1)\n",
    "std_dev = np.std(data, ddof=1)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Mode: {mode}\")\n",
    "print(f\"Variance: {variance:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "\n",
    "# The median (44.5) or mode (45) would be most appropriate because\n",
    "# the data has some extreme values (12, 89) that pull the mean.\n",
    "# The median is robust to outliers.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Bayes' Theorem\n",
    "\n",
    "A spam filter is 98% accurate at identifying spam emails (true positive rate) and 95% accurate at identifying legitimate emails (true negative rate). If 20% of all emails are spam, what is the probability that an email flagged as spam is actually spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "p_spam = 0.20\n",
    "p_flagged_given_spam = 0.98\n",
    "p_flagged_given_not_spam = 0.05\n",
    "\n",
    "p_flagged = (p_flagged_given_spam * p_spam + \n",
    "             p_flagged_given_not_spam * (1 - p_spam))\n",
    "\n",
    "p_spam_given_flagged = (p_flagged_given_spam * p_spam) / p_flagged\n",
    "\n",
    "print(f\"P(Flagged) = {p_flagged:.4f}\")\n",
    "print(f\"P(Spam | Flagged) = {p_spam_given_flagged:.2%}\")\n",
    "\n",
    "# Answer: ~83.05% - Even with high accuracy, about 17% of flagged\n",
    "# emails are actually legitimate (false positives)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Probability Distributions\n",
    "\n",
    "A call centre receives an average of 5 calls per minute. Using the Poisson distribution:\n",
    "1. What is the probability of receiving exactly 3 calls in a minute?\n",
    "2. What is the probability of receiving at most 2 calls in a minute?\n",
    "3. What is the probability of receiving more than 7 calls in a minute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "lambda_rate = 5\n",
    "poisson = stats.poisson(mu=lambda_rate)\n",
    "\n",
    "p_exactly_3 = poisson.pmf(3)\n",
    "print(f\"P(X = 3) = {p_exactly_3:.4f}\")\n",
    "\n",
    "p_at_most_2 = poisson.cdf(2)\n",
    "print(f\"P(X <= 2) = {p_at_most_2:.4f}\")\n",
    "\n",
    "p_more_than_7 = 1 - poisson.cdf(7)\n",
    "print(f\"P(X > 7) = {p_more_than_7:.4f}\")\n",
    "\n",
    "# Answers:\n",
    "# 1. P(X = 3) = 0.1404 (about 14%)\n",
    "# 2. P(X <= 2) = 0.1247 (about 12.5%)\n",
    "# 3. P(X > 7) = 0.1334 (about 13.3%)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Central Limit Theorem\n",
    "\n",
    "A population has a mean of 100 and standard deviation of 20. If you take samples of size 64:\n",
    "1. What is the expected mean of the sampling distribution?\n",
    "2. What is the standard error?\n",
    "3. What is the probability that a sample mean will be greater than 105?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "mu = 100\n",
    "sigma = 20\n",
    "n = 64\n",
    "\n",
    "sampling_mean = mu\n",
    "standard_error = sigma / np.sqrt(n)\n",
    "\n",
    "print(f\"1. Expected mean of sampling distribution: {sampling_mean}\")\n",
    "print(f\"2. Standard error: {standard_error}\")\n",
    "\n",
    "sampling_dist = stats.norm(loc=sampling_mean, scale=standard_error)\n",
    "p_greater_than_105 = 1 - sampling_dist.cdf(105)\n",
    "\n",
    "print(f\"3. P(sample mean > 105) = {p_greater_than_105:.4f}\")\n",
    "\n",
    "# Answers:\n",
    "# 1. 100 (same as population mean)\n",
    "# 2. 2.5 (20 / sqrt(64) = 20/8 = 2.5)\n",
    "# 3. 0.0228 (about 2.3%)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Confidence Intervals\n",
    "\n",
    "A sample of 36 students has a mean test score of 72 with a standard deviation of 12. Calculate:\n",
    "1. The 95% confidence interval for the population mean\n",
    "2. The 99% confidence interval for the population mean\n",
    "3. How would the interval change if the sample size was 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "n = 36\n",
    "mean = 72\n",
    "std = 12\n",
    "se = std / np.sqrt(n)\n",
    "\n",
    "ci_95 = stats.t.interval(0.95, df=n-1, loc=mean, scale=se)\n",
    "print(f\"1. 95% CI: ({ci_95[0]:.2f}, {ci_95[1]:.2f})\")\n",
    "\n",
    "ci_99 = stats.t.interval(0.99, df=n-1, loc=mean, scale=se)\n",
    "print(f\"2. 99% CI: ({ci_99[0]:.2f}, {ci_99[1]:.2f})\")\n",
    "\n",
    "n_large = 100\n",
    "se_large = std / np.sqrt(n_large)\n",
    "ci_95_large = stats.t.interval(0.95, df=n_large-1, loc=mean, scale=se_large)\n",
    "print(f\"3. 95% CI with n=100: ({ci_95_large[0]:.2f}, {ci_95_large[1]:.2f})\")\n",
    "\n",
    "# The interval becomes narrower with larger sample size\n",
    "# because the standard error decreases.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Hypothesis Testing (t-test)\n",
    "\n",
    "A company claims their energy drink increases reaction time. In a study, 25 participants had a mean reaction time improvement of 15ms with a standard deviation of 30ms. At a significance level of 0.05, is there sufficient evidence to support the company's claim?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "n = 25\n",
    "mean_improvement = 15\n",
    "std = 30\n",
    "alpha = 0.05\n",
    "h0_mean = 0\n",
    "\n",
    "se = std / np.sqrt(n)\n",
    "t_stat = (mean_improvement - h0_mean) / se\n",
    "\n",
    "p_value = 1 - stats.t.cdf(t_stat, df=n-1)\n",
    "\n",
    "print(f\"H0: mu <= 0 (no improvement)\")\n",
    "print(f\"H1: mu > 0 (improvement exists)\")\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value (one-tailed): {p_value:.4f}\")\n",
    "print(f\"\\nReject H0: {p_value < alpha}\")\n",
    "\n",
    "# With p-value = 0.0109 < 0.05, we reject the null hypothesis.\n",
    "# There is sufficient evidence to support the company's claim.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Chi-Square Test\n",
    "\n",
    "A marketing team ran a campaign across three channels (Email, Social Media, Direct Mail) and tracked conversions. The observed results are:\n",
    "- Email: 120 conversions, 880 no conversion\n",
    "- Social Media: 150 conversions, 850 no conversion  \n",
    "- Direct Mail: 80 conversions, 920 no conversion\n",
    "\n",
    "Is there a significant difference in conversion rates between channels at α = 0.05?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "observed = np.array([\n",
    "    [120, 880],\n",
    "    [150, 850],\n",
    "    [80, 920]\n",
    "])\n",
    "\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(\"Observed:\")\n",
    "print(observed)\n",
    "print(f\"\\nExpected:\")\n",
    "print(expected.round(2))\n",
    "print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"\\nReject H0 (channels are independent): {p_value < 0.05}\")\n",
    "\n",
    "# With p-value < 0.05, we reject H0.\n",
    "# There is a significant difference in conversion rates between channels.\n",
    "# Social Media has the highest conversion rate (15%), \n",
    "# followed by Email (12%), then Direct Mail (8%).\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Correlation Analysis\n",
    "\n",
    "Given the following data on hours studied and exam scores:\n",
    "- Hours: [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "- Scores: [55, 60, 68, 75, 80, 85, 88, 92]\n",
    "\n",
    "1. Calculate the Pearson correlation coefficient\n",
    "2. Test if the correlation is statistically significant at α = 0.05\n",
    "3. Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "hours = np.array([2, 4, 6, 8, 10, 12, 14, 16])\n",
    "scores = np.array([55, 60, 68, 75, 80, 85, 88, 92])\n",
    "\n",
    "r, p_value = stats.pearsonr(hours, scores)\n",
    "\n",
    "print(f\"1. Pearson correlation coefficient (r): {r:.4f}\")\n",
    "print(f\"2. p-value: {p_value:.6f}\")\n",
    "print(f\"   Significant at α=0.05: {p_value < 0.05}\")\n",
    "\n",
    "print(f\"\\n3. Interpretation:\")\n",
    "print(f\"   - r = {r:.3f} indicates a very strong positive correlation\")\n",
    "print(f\"   - p-value < 0.05 means the correlation is statistically significant\")\n",
    "print(f\"   - R-squared = {r**2:.3f}, meaning {r**2*100:.1f}% of score variance\")\n",
    "print(f\"     can be explained by hours studied\")\n",
    "print(f\"   - Note: Correlation does not prove causation!\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: A/B Testing\n",
    "\n",
    "An e-commerce website ran an A/B test on their checkout page:\n",
    "- Control (A): 4,500 visitors, 225 purchases\n",
    "- Treatment (B): 4,700 visitors, 282 purchases\n",
    "\n",
    "1. Calculate the conversion rate for each group\n",
    "2. Perform a hypothesis test at α = 0.05\n",
    "3. Calculate the relative lift\n",
    "4. Should the company implement the new design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "conversions_a, total_a = 225, 4500\n",
    "conversions_b, total_b = 282, 4700\n",
    "\n",
    "rate_a = conversions_a / total_a\n",
    "rate_b = conversions_b / total_b\n",
    "print(f\"1. Conversion Rates:\")\n",
    "print(f\"   Control (A): {rate_a:.2%}\")\n",
    "print(f\"   Treatment (B): {rate_b:.2%}\")\n",
    "\n",
    "count = np.array([conversions_a, conversions_b])\n",
    "nobs = np.array([total_a, total_b])\n",
    "z_stat, p_value = proportions_ztest(count, nobs, alternative='two-sided')\n",
    "\n",
    "print(f\"\\n2. Hypothesis Test:\")\n",
    "print(f\"   z-statistic: {z_stat:.4f}\")\n",
    "print(f\"   p-value: {p_value:.4f}\")\n",
    "print(f\"   Significant at α=0.05: {p_value < 0.05}\")\n",
    "\n",
    "relative_lift = (rate_b - rate_a) / rate_a * 100\n",
    "print(f\"\\n3. Relative lift: {relative_lift:.1f}%\")\n",
    "\n",
    "print(f\"\\n4. Recommendation:\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"   Yes, the company should implement the new design.\")\n",
    "    print(f\"   The improvement is statistically significant with\")\n",
    "    print(f\"   a {relative_lift:.1f}% increase in conversion rate.\")\n",
    "else:\n",
    "    print(f\"   No clear recommendation - results are not significant.\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Sample Size Calculation\n",
    "\n",
    "A data scientist wants to detect a 5% relative improvement in conversion rate from a baseline of 10%. Calculate the required sample size per group for:\n",
    "1. 80% power and α = 0.05\n",
    "2. 90% power and α = 0.05\n",
    "3. Explain why these numbers differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "\n",
    "def calculate_sample_size(baseline, mde, alpha, power):\n",
    "    p1 = baseline\n",
    "    p2 = baseline * (1 + mde)\n",
    "    pooled_p = (p1 + p2) / 2\n",
    "    effect_size = abs(p2 - p1) / np.sqrt(pooled_p * (1 - pooled_p))\n",
    "    \n",
    "    analysis = NormalIndPower()\n",
    "    n = analysis.solve_power(\n",
    "        effect_size=effect_size,\n",
    "        alpha=alpha,\n",
    "        power=power,\n",
    "        alternative='two-sided'\n",
    "    )\n",
    "    return int(np.ceil(n))\n",
    "\n",
    "baseline = 0.10\n",
    "mde = 0.05\n",
    "\n",
    "n_80 = calculate_sample_size(baseline, mde, alpha=0.05, power=0.80)\n",
    "n_90 = calculate_sample_size(baseline, mde, alpha=0.05, power=0.90)\n",
    "\n",
    "print(f\"1. Sample size per group (80% power): {n_80:,}\")\n",
    "print(f\"   Total sample size: {n_80 * 2:,}\")\n",
    "\n",
    "print(f\"\\n2. Sample size per group (90% power): {n_90:,}\")\n",
    "print(f\"   Total sample size: {n_90 * 2:,}\")\n",
    "\n",
    "print(f\"\\n3. Explanation:\")\n",
    "print(f\"   Higher power (90% vs 80%) requires larger sample sizes because:\")\n",
    "print(f\"   - Power = 1 - beta (probability of detecting true effect)\")\n",
    "print(f\"   - To reduce Type II errors (false negatives), we need more data\")\n",
    "print(f\"   - The 90% power test needs ~{(n_90/n_80 - 1)*100:.0f}% more samples\")\n",
    "print(f\"   - Trade-off: More samples = higher cost but more reliable results\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11: Multiple Testing Correction\n",
    "\n",
    "A researcher tests 20 different hypotheses and gets the following p-values:\n",
    "`[0.001, 0.008, 0.015, 0.022, 0.031, 0.04, 0.048, 0.055, 0.06, 0.08, 0.12, 0.15, 0.23, 0.34, 0.45, 0.56, 0.67, 0.78, 0.89, 0.95]`\n",
    "\n",
    "1. How many hypotheses would be rejected at α = 0.05 without correction?\n",
    "2. Apply Bonferroni correction - how many are significant now?\n",
    "3. Why is correction necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "p_values = np.array([0.001, 0.008, 0.015, 0.022, 0.031, 0.04, 0.048, 0.055,\n",
    "                     0.06, 0.08, 0.12, 0.15, 0.23, 0.34, 0.45, 0.56, \n",
    "                     0.67, 0.78, 0.89, 0.95])\n",
    "\n",
    "alpha = 0.05\n",
    "n_tests = len(p_values)\n",
    "\n",
    "sig_uncorrected = sum(p_values < alpha)\n",
    "print(f\"1. Significant without correction (α={alpha}): {sig_uncorrected}\")\n",
    "\n",
    "bonferroni_alpha = alpha / n_tests\n",
    "sig_bonferroni = sum(p_values < bonferroni_alpha)\n",
    "print(f\"\\n2. Bonferroni correction:\")\n",
    "print(f\"   Corrected α = {alpha}/{n_tests} = {bonferroni_alpha:.4f}\")\n",
    "print(f\"   Significant after correction: {sig_bonferroni}\")\n",
    "print(f\"   Significant p-values: {p_values[p_values < bonferroni_alpha]}\")\n",
    "\n",
    "print(f\"\\n3. Why correction is necessary:\")\n",
    "print(f\"   - Without correction, we expect {n_tests * alpha:.0f} false positives by chance\")\n",
    "print(f\"   - This is the 'multiple comparisons problem'\")\n",
    "print(f\"   - P(at least one false positive) = 1 - (1-α)^{n_tests} = {1 - (1-alpha)**n_tests:.2%}\")\n",
    "print(f\"   - Bonferroni controls family-wise error rate at α\")\n",
    "print(f\"   - Trade-off: More conservative, may miss true effects\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: Interpreting Statistical Results\n",
    "\n",
    "A study reports: \"We found a statistically significant correlation between ice cream sales and drowning deaths (r = 0.87, p < 0.001, n = 365).\"\n",
    "\n",
    "1. What can you conclude from this result?\n",
    "2. What can you NOT conclude?\n",
    "3. What is a likely explanation for this correlation?\n",
    "4. What additional analysis would you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here (this is more conceptual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "# 1. What you CAN conclude:\n",
    "#    - There is a strong positive linear relationship (r = 0.87)\n",
    "#    - The correlation is statistically significant (p < 0.001)\n",
    "#    - With 365 observations, we have good sample size\n",
    "#    - When ice cream sales increase, drowning deaths also tend to increase\n",
    "\n",
    "# 2. What you CANNOT conclude:\n",
    "#    - Ice cream causes drowning\n",
    "#    - Drowning causes ice cream sales\n",
    "#    - Reducing ice cream sales would reduce drowning deaths\n",
    "#    - Any causal relationship between the two variables\n",
    "\n",
    "# 3. Likely explanation:\n",
    "#    - This is a classic example of a CONFOUNDING VARIABLE\n",
    "#    - Temperature/Season is the lurking variable\n",
    "#    - Hot weather leads to both:\n",
    "#      a) More ice cream consumption\n",
    "#      b) More swimming, thus more drowning risk\n",
    "#    - This is called SPURIOUS CORRELATION\n",
    "\n",
    "# 4. Recommended additional analysis:\n",
    "#    - Control for temperature/season using:\n",
    "#      a) Partial correlation analysis\n",
    "#      b) Multiple regression with temperature as covariate\n",
    "#      c) Stratified analysis by season\n",
    "#    - Examine the relationship within each season\n",
    "#    - Look for other potential confounders\n",
    "#    - Consider a causal inference framework (e.g., DAGs)\n",
    "\n",
    "print(\"Key Takeaway: CORRELATION DOES NOT IMPLY CAUSATION\")\n",
    "print(\"\\nAlways consider:\")\n",
    "print(\"1. Confounding variables\")\n",
    "print(\"2. Reverse causality\")\n",
    "print(\"3. Coincidental correlation\")\n",
    "print(\"4. Selection bias\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This crash course covered the essential statistics concepts for data science interviews:\n",
    "\n",
    "1. **Descriptive Statistics** - Summarising data with measures of central tendency and dispersion\n",
    "2. **Probability** - Conditional probability and Bayes' theorem for reasoning under uncertainty\n",
    "3. **Distributions** - Normal, Binomial, Poisson, and Uniform distributions\n",
    "4. **Central Limit Theorem** - Foundation for statistical inference\n",
    "5. **Confidence Intervals** - Quantifying uncertainty in estimates\n",
    "6. **Hypothesis Testing** - Making decisions based on data\n",
    "7. **Correlation** - Measuring relationships between variables\n",
    "8. **A/B Testing** - Experimental design for comparing treatments\n",
    "9. **Sampling Methods** - Techniques for collecting representative data\n",
    "10. **Statistical Pitfalls** - Common mistakes to avoid\n",
    "\n",
    "### Key Interview Tips\n",
    "\n",
    "- Always state your assumptions clearly\n",
    "- Distinguish between statistical significance and practical significance\n",
    "- Remember: correlation does not imply causation\n",
    "- Consider sample size and potential biases\n",
    "- Know when to use parametric vs non-parametric tests\n",
    "- Understand the difference between Type I and Type II errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "- [DataCamp - Top 35 Statistics Interview Questions (2026)](https://www.datacamp.com/blog/statistics-interview-questions)\n",
    "- [Data Interview - 120 Statistics Interview Questions](https://www.datainterview.com/blog/statistics-interview-questions)\n",
    "- [Analytics Vidhya - Top 100 Data Science Interview Questions](https://www.analyticsvidhya.com/blog/2026/01/data-science-interview-questions/)\n",
    "- [Statistics LibreTexts - Hypothesis Test for Correlation](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Mostly_Harmless_Statistics_(Webb)/12:_Correlation_and_Regression/12.01:_Correlation/12.1.02:_Hypothesis_Test_for_a_Correlation)\n",
    "- [Penn State STAT 501 - Hypothesis Test for Correlation](https://online.stat.psu.edu/stat501/lesson/1/1.9)\n",
    "- [SciPy Documentation](https://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview-crash-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}